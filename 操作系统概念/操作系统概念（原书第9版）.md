@[toc](Contens)

# 第二部分 进程管理

## 第3章 进程

### 3.1 进程概念

+ 进程包括程序（文本段）、程序计数器、堆栈以及数据段等。
+ 进程状态：
  + 新的（new）
  + 运行（running）
  + 等待（waiting）
  + 就绪（ready）
  + 终止（terminated）
+ 进程控制块（PCB）包括：
  + 进程状态
  + 程序计数器
  + CPU寄存器
  + CPU调度信息
  + 内存管理信息
  + 记账信息
  + I/O状态信息

### 3.2 进程调度

+ **多道程序设计**的目标是，无论何时都有进程运行，从而最大化CPU利用率。
+ **分时系统**的目的是在进程之间快速切换CPU，以便用户在程序运行时能与其交互。
+ 等待CPU的有个就绪队列来存放进程，等待某个设备的也有相应的设备队列。
+ **长期调度程序**和**短期调度程序**。
  + 长期调度程序从缓冲池中选择进程，加到**内存**，以便执行。
  + 短期调度程序从准备执行的进程中选择进程，并分配**CPU**。
  + 这两种调度程序的主要区别是**执行频率**，短期调度必须经常为CPU选择新的进程，而长期调度程序执行并不频繁。重要的是，**长期调度程序进行认真选择**。

### 3.4 进程间通信

+ 提供环境允许进程协作的理由：
  + **信息共享**。
  + **计算加速**
  + **模块化**
  + **方便**：即使单个用户也可能同时执行很多任务。例如，用户可以并行地编辑、收听音乐、编译。
+ 进程间通信有两种基本模型：**共享内存**和**消息传递**。
  + 共享内存模型会建立起一块供协作进程共享的内存区域，进程通过向此共享区域读出或写入数据来交换信息。
  + 消息传递模型通过协作进程间交换消息来实现通信。
  + 消息传递对于交换较少数量的数据很有用，因为无需避免冲突。共享内存可以快于消息传递，这是因为消息传递的实现进场采用系统调用，因此需要消耗更多时间以便内核介入。与此相反，共享内存系统仅在建立共享内存区域时需要系统调用，一旦建立共享内存，所有访问都可以作为常规内存访问，无需借助内核。

### 3.6 客户机/服务器通信

+ 共享内存和消息传递这两种技术也可以用于客户机/服务器系统的通信。客户机/服务器系统还有其他三种策略：套接字、远程程序调用和管道。



## 第4章 多线程编程

### 4.1 概述

+ 动机：进程创建很耗时间和资源。如果新进程与原进程执行同样的任务，为什么要承担所有这些开销。
+ 多线程编程的优点：
  + **响应性**。如果一个交互程序采用多线程，那么即使部分阻塞或者执行冗长操作，它仍可以继续执行，从而增加对用户的响应程度。
  + **资源共享**。进程只能通过共享内存或消息传递之类的技术共享内存，并且需要程序员显示地安排。而线程默认共享它们所属进程的内存和资源。
  + **经济**
  + **可伸缩性**。对于多处理器体系结构，线程可以在多处理核上并行运行。

### 4.3 多线程模型

+ 多对一模型。映射多个用户线程到一个内核线程。
+ 一对一模型。映射每个用户线程到一个内核线程。
+ 多对多模型。多路复用多个用户线程到同样数量或更少数量的内核线程。

### 4.5 隐式多线程

+ 将多线程的创建与管理交给编译器和运行时库来完成。这种策略称为**隐式线程**（implicit threading）。
+ **线程池的主要思想**是：在进程开始时，创建一定数量的线程，并加到池中以等待工作。当服务器收到请求时，它会唤醒池内的一个线程（如果有可用线程），并将需要服务的请求传递给它。一旦线程完成了服务，它会返回池中再等待工作。如果池中没有可用线程，那么服务器会等待，直到有空线程为止。
+ **线程池的优点**：
  + 用现有线程服务请求比等待创建一个线程更快。
  + 线程池限制了在任何时候可用线程的数量。对于不能支持大量并发线程的系统比较重要。
  + 将要执行的任务从创建任务的机制中分离出来，允许我们采用不同策略运行任务。如定期执行等。

## 第5章 进程调度

### 5.1 基本概念

+ 需要CPU调度的情况可以分为以下四种：
  + 当一个进程从运行状态切换到等待状态时。如I/O请求，或wait()调用，以便等待一个子进程终止。
  + 当一个进程从运行状态切换到就绪状态时。如出现中断时。
  + 当一个进程从等待状态切换到就绪状态时。如I/O完成时。
  + 当一个进程终止时。

### 5.3 调度算法

+ **先到先服务（FCFS）**。缺点是平均等待时间往往很长。
+ **最短作业优先调度（SJF）**。经常用于长期调度。虽然SJF是最优的，但是不能在短期CPU调度级别上实现，因为不知道下次CPU执行的长度。
+ **优先级调度**。低优先级进程的无穷等待问题的解决方案之一是老化。逐渐增加在系统中等待时间很长的进程的优先级。
+ **轮转调度（RR）**。
+ **多级队列调度**。将就绪队列分成多个单独队列，一个进程被永久分到一个队列。每个队列有自己的调度算法，不同队列之间通常采用固定优先级抢占调度。
+ **多级反馈队列调度**。允许进程在队列之间迁移。

## 第6章 同步

### 6.2 临界区问题

+ 每个进程有一段代码，称为**临界区**（critical section），进程在执行该区时可能修改公共变量、更新一个表、写一个文件等。当一个进程在临界区内执行时，其他进程不允许在它们的临界区内执行。
+ 临界区问题是，设计一个协议以便协作进程。在进入临界区前，每个进程应请求许可。实现这一请求的代码区段称为**进入区**。临界区之后可以有**退出区**，其他代码为**剩余区**。
+ 临界区问题的解决方案应该满足如下三条要求
  + **互斥**。如果进程 $P_{i}$ 在其临界区内执行，那么其他进程都不能在其临界区内执行。
  + **进步**（progress）。
  + **有限等待**。

## 第7章 死锁

## 7.2 死锁特征

+ 死锁的必要条件
  + 互斥
  + 占有并等待
  + 非抢占
  + 循环等待

### 7.3 死锁处理方法

+ 一般来说，处理死锁问题有三种方法：
  + 通过协议来预防或避免死锁，确保系统不会进入死锁状态。
  + 可以允许系统进入死锁状态，然后检测它，并加以恢复。
  + 可以忽视这个问题，认为死锁不可能在系统内发生。**这个第三种方案是大多数操作系统所使用的。**

### 7.5 死锁避免

+ **安全状态**
  + 如果系统能按一定顺序为每个进程分配资源（不超过它的最大需求），仍然避免死锁，那么系统的状态就是安全的。
  + 当有进程申请一个可用资源时，系统应确定：这一资源申请是可以立即分配，还是应该让进程等待。只有在分配后系统仍处于安全状态，才能允许申请。
+ 资源分配图算法
  + 有申请边，分配边和需求边，只有当把申请边转化为需求边时不会产生环，才允许申请。通过采用环检测算法来检查安全性。可以通过深搜来检查是否有环。
+ 银行家算法
  + 对于每种资源类型有多个实例的资源分配系统，资源分配图算法就不适用了。这时可用银行家算法。
  + **安全算法**。判断系统当前状态是否是安全状态。
  + **资源请求算法**。

### 7.6 死锁检测

+ 每种资源只有单个实例时，可以用**等待图**。
  + 等待图就是从资源分配图中删除所有的资源类型节点，合并适当边，来表示进程之间的等待关系。
  + 当且仅当在等待图中存在环时，系统存在死锁。
+ 每种资源可能有多个实例时，可以用一种类似于银行家算法的死锁检测算法。

### 7.7 死锁恢复

+ 打破死锁有两个选择

  + 一个是，简单地中止一个或多个进程来打破循环等待。

    + 中止所有死锁进程
    + 一次中止一个死锁进程，直到消除死锁循环为止

  + 另一个是，从一个或多个死锁进程那里抢占一个或多个资源。

    