@[toc](Contens)

# 第二部分 进程管理

## 第3章 进程

### 3.1 进程概念

+ 进程包括程序（文本段）、程序计数器、堆栈以及数据段等。
+ 进程状态：
  + 新的（new）
  + 运行（running）
  + 等待（waiting）
  + 就绪（ready）
  + 终止（terminated）
+ 进程控制块（PCB）包括：
  + 进程状态
  + 程序计数器
  + CPU寄存器
  + CPU调度信息
  + 内存管理信息
  + 记账信息
  + I/O状态信息

### 3.2 进程调度

+ **多道程序设计**的目标是，无论何时都有进程运行，从而最大化CPU利用率。
+ **分时系统**的目的是在进程之间快速切换CPU，以便用户在程序运行时能与其交互。
+ 等待CPU的有个就绪队列来存放进程，等待某个设备的也有相应的设备队列。
+ **长期调度程序**和**短期调度程序**。
  + 长期调度程序从缓冲池中选择进程，加到**内存**，以便执行。
  + 短期调度程序从准备执行的进程中选择进程，并分配**CPU**。
  + 这两种调度程序的主要区别是**执行频率**，短期调度必须经常为CPU选择新的进程，而长期调度程序执行并不频繁。重要的是，**长期调度程序进行认真选择**。

### 3.4 进程间通信

+ 提供环境允许进程协作的理由：
  + **信息共享**。
  + **计算加速**
  + **模块化**
  + **方便**：即使单个用户也可能同时执行很多任务。例如，用户可以并行地编辑、收听音乐、编译。
+ 进程间通信有两种基本模型：**共享内存**和**消息传递**。
  + 共享内存模型会建立起一块供协作进程共享的内存区域，进程通过向此共享区域读出或写入数据来交换信息。
  + 消息传递模型通过协作进程间交换消息来实现通信。
  + 消息传递对于交换较少数量的数据很有用，因为无需避免冲突。共享内存可以快于消息传递，这是因为消息传递的实现进场采用系统调用，因此需要消耗更多时间以便内核介入。与此相反，共享内存系统仅在建立共享内存区域时需要系统调用，一旦建立共享内存，所有访问都可以作为常规内存访问，无需借助内核。

### 3.6 客户机/服务器通信

+ 共享内存和消息传递这两种技术也可以用于客户机/服务器系统的通信。客户机/服务器系统还有其他三种策略：套接字、远程程序调用和管道。



## 第4章 多线程编程

### 4.1 概述

+ 动机：进程创建很耗时间和资源。如果新进程与原进程执行同样的任务，为什么要承担所有这些开销。
+ 多线程编程的优点：
  + **响应性**。如果一个交互程序采用多线程，那么即使部分阻塞或者执行冗长操作，它仍可以继续执行，从而增加对用户的响应程度。
  + **资源共享**。进程只能通过共享内存或消息传递之类的技术共享内存，并且需要程序员显示地安排。而线程默认共享它们所属进程的内存和资源。
  + **经济**
  + **可伸缩性**。对于多处理器体系结构，线程可以在多处理核上并行运行。

### 4.3 多线程模型

+ 多对一模型。映射多个用户线程到一个内核线程。
+ 一对一模型。映射每个用户线程到一个内核线程。
+ 多对多模型。多路复用多个用户线程到同样数量或更少数量的内核线程。

### 4.5 隐式多线程

+ 将多线程的创建与管理交给编译器和运行时库来完成。这种策略称为**隐式线程**（implicit threading）。
+ **线程池的主要思想**是：在进程开始时，创建一定数量的线程，并加到池中以等待工作。当服务器收到请求时，它会唤醒池内的一个线程（如果有可用线程），并将需要服务的请求传递给它。一旦线程完成了服务，它会返回池中再等待工作。如果池中没有可用线程，那么服务器会等待，直到有空线程为止。
+ **线程池的优点**：
  + 用现有线程服务请求比等待创建一个线程更快。
  + 线程池限制了在任何时候可用线程的数量。对于不能支持大量并发线程的系统比较重要。
  + 将要执行的任务从创建任务的机制中分离出来，允许我们采用不同策略运行任务。如定期执行等。

## 第5章 进程调度

### 5.1 基本概念

+ 需要CPU调度的情况可以分为以下四种：
  + 当一个进程从运行状态切换到等待状态时。如I/O请求，或wait()调用，以便等待一个子进程终止。
  + 当一个进程从运行状态切换到就绪状态时。如出现中断时。
  + 当一个进程从等待状态切换到就绪状态时。如I/O完成时。
  + 当一个进程终止时。

### 5.3 调度算法

+ **先到先服务（FCFS）**。缺点是平均等待时间往往很长。
+ **最短作业优先调度（SJF）**。经常用于长期调度。虽然SJF是最优的，但是不能在短期CPU调度级别上实现，因为不知道下次CPU执行的长度。
+ **优先级调度**。低优先级进程的无穷等待问题的解决方案之一是老化。逐渐增加在系统中等待时间很长的进程的优先级。
+ **轮转调度（RR）**。
+ **多级队列调度**。将就绪队列分成多个单独队列，一个进程被永久分到一个队列。每个队列有自己的调度算法，不同队列之间通常采用固定优先级抢占调度。
+ **多级反馈队列调度**。允许进程在队列之间迁移。

## 第6章 同步

### 6.2 临界区问题

+ 每个进程有一段代码，称为**临界区**（critical section），进程在执行该区时可能修改公共变量、更新一个表、写一个文件等。当一个进程在临界区内执行时，其他进程不允许在它们的临界区内执行。
+ 临界区问题是，设计一个协议以便协作进程。在进入临界区前，每个进程应请求许可。实现这一请求的代码区段称为**进入区**。临界区之后可以有**退出区**，其他代码为**剩余区**。
+ 临界区问题的解决方案应该满足如下三条要求
  + **互斥**。如果进程 $P_{i}$ 在其临界区内执行，那么其他进程都不能在其临界区内执行。
  + **进步**（progress）。
  + **有限等待**。

## 第7章 死锁

## 7.2 死锁特征

+ 死锁的必要条件
  + 互斥
  + 占有并等待
  + 非抢占
  + 循环等待

### 7.3 死锁处理方法

+ 一般来说，处理死锁问题有三种方法：
  + 通过协议来预防或避免死锁，确保系统不会进入死锁状态。
  + 可以允许系统进入死锁状态，然后检测它，并加以恢复。
  + 可以忽视这个问题，认为死锁不可能在系统内发生。**这个第三种方案是大多数操作系统所使用的。**

### 7.5 死锁避免

+ **安全状态**
  + 如果系统能按一定顺序为每个进程分配资源（不超过它的最大需求），仍然避免死锁，那么系统的状态就是安全的。
  + 当有进程申请一个可用资源时，系统应确定：这一资源申请是可以立即分配，还是应该让进程等待。只有在分配后系统仍处于安全状态，才能允许申请。
+ 资源分配图算法
  + 有申请边，分配边和需求边，只有当把申请边转化为需求边时不会产生环，才允许申请。通过采用环检测算法来检查安全性。可以通过深搜来检查是否有环。
+ 银行家算法
  + 对于每种资源类型有多个实例的资源分配系统，资源分配图算法就不适用了。这时可用银行家算法。
  + **安全算法**。判断系统当前状态是否是安全状态。
  + **资源请求算法**。

### 7.6 死锁检测

+ 每种资源只有单个实例时，可以用**等待图**。
  + 等待图就是从资源分配图中删除所有的资源类型节点，合并适当边，来表示进程之间的等待关系。
  + 当且仅当在等待图中存在环时，系统存在死锁。
+ 每种资源可能有多个实例时，可以用一种类似于银行家算法的死锁检测算法。

### 7.7 死锁恢复

+ 打破死锁有两个选择

  + 一个是，简单地中止一个或多个进程来打破循环等待。

    + 中止所有死锁进程
    + 一次中止一个死锁进程，直到消除死锁循环为止

  + 另一个是，从一个或多个死锁进程那里抢占一个或多个资源。


# 第三部分 内存管理

## 第8章 内存管理策略

### 8.1 背景

+ 基地址寄存器， 界限地址寄存器
+ 指令和数据绑定到存储器地址可在沿途的任何一步中进行：
  + 编译时
  + 加载时
  + 执行时
+ CPU生成的地址通常称为**逻辑地址**，而内存单元看到的地址（即加载到内存地址寄存器的地址）通常称为**物理地址**。
+ 为了获得更好的内存空间利用率，可以使用**动态加载（dynamic loading）**。采用动态加载时，一个程序只有在调用时才会加载。所有程序都以可重定位加载格式保存在磁盘上。主程序被加载到内存，并执行。当一个程序需要调用另一个程序时，调用程序会首先检查另一个程序是否已经被加载。如果没有，可重定位链接程序会加载所需的程序到内存，并更新程序的地址表以反映这一变化。接着，控制传递给新加载的程序。
+ **动态链接库（dynamic linked library）**为系统库，可链接到用户程序，以便运行。
  + 动态链接也可用于库的更新（如修改bug）。一个库可以被新的版本所替代，而且使用该库的所有程序会自动使用新的版本。

### 8.2 交换

+ 进程必须在内存中以便执行，不过，进程可以暂时从内存**交换（swap）**到备份存储，当再次执行时再调回到内存中。
  + 交换可能让所有进程的总的物理地址空间超过真实系统的物理地址空间，从而增加了系统的多道程序程度。
  + 现代操作系统并不使用标准交换，而是使用一些交换的变种。一个常用的变种是：正常情况下，禁止交换；当空闲内存（未被操作系统或进程使用的内存）低于某个阈值时，启用交换。

### 8.3 连续内存分配

+ 内存通常分为两个区域：一个用于驻留操作系统，另一个用于用户进程。操作系统可以放在低内存，也可放在高内存。
+ 最简单的内存分配方法之一，就是将内存分为多个**固定大小的分区**（partition）。每个分区可以只包含一个进程。因此，多道程序受限于分区数，现在该方法已不再使用。
+ **可变分区**方案。
  + 可用的内存块为分散在内存里的不同大小的孔的集合。当新进程需要内存时，系统为该进程查找足够大的孔。如果孔太大，那么就分为两块：一块分配给新的进程，另一块还回到孔集合。当进程终止时，它将释放内存，该内存将还给孔的集合。如果新孔与其他孔相邻，那么将这些孔合并成大孔。
  + 从一组可用孔中选择一个空闲孔的最为常用的方法包括：
    + **首次适应**：分配首个足够大的孔。
    + **最优适应**：分配最小的足够大的孔。
    + **最差适应**：分配最大的孔。
  + 首次适应和最优适应在执行时间和利用空间方面都好于最差适应。首次适应和最优适应在利用空间方面难分伯仲，但是首次适应要更快些。
+ **内部碎片**与**外部碎片**
  + 外部碎片的一种解决方案是**紧缩（compaction）**。它的目的是移动内存内容，以便将所有空闲空间合并成一整块。如果重定位是静态的，并且在编译或加载时进行的，那么就不能紧缩。
  + 另一种解决方案是允许进程的逻辑地址空间是不连续的。（分段，分页）

### 8.4 分段

+ 分段（segmentation）。允许进程的物理地址空间是非连续的。

### 8.5 分页

+ 分页避免了外部碎片和紧缩，而分段不可以。
+ 将物理内存分为固定大小的块，称为**帧**（frame）；将逻辑内存也分为同样大小的块，称为**页**（page）。
+ **帧表**：记录哪些帧已分配，哪些帧空闲，总共有多少帧等。
+ 转换表缓冲区（TLB）
+ **共享页**，分页的优点之一是可以共享公共代码。

### 8.6 页表结构

+ 页表有可能非常大，一种方法是使用两层分页算法，就是将页表再分页。

## 第9章 虚拟内存管理

+ 虚拟内存技术允许执行进程不必完全处于内存。这种方案的一个主要优点就是，**程序可以大于物理内存**。此外，虚拟内存将内存抽象成一个巨大的，统一的数组，进而实现了用户看到的**逻辑内存与物理内存的分离**。

### 9.1 背景

+ 在许多情况下，不需要将整个内存置于内存中。
  + 程序通常具有处理异常错误条件的代码。
  + 数组、链表和表等所分配的内存量通常多于实际需要值。
  + 程序的某些选项和功能可能很少使用。
+ 虚拟内存将用户逻辑与物理内存分开。这在现有物理内存有限的情况下，为程序员提供了巨大的虚拟内存。虚拟内存使得编程更加容易，因为程序员不再需要担心有限的物理内存空间，只需要关注所要解决的问题。
+ 虚拟内存允许文件和内存通过共享页面而为多个进程所共享。

### 9.2 请求调页

+ **缺页错误**（page fault）。对标记为无效的页面访问会产生缺页错误。
+ 页错误处理时间有三个主要组成部分：
  + 处理缺页错误中断。
  + 读入页面。
  + 重新启动进程。

### 9.3 写时复制

+ 子进程与父进程共享的页面，如果有一方需要修改页面中的内容，需要先复制一份，然后在副本上操作，这就是**写时复制**。

### 9.4 页面置换

+ **页面置换**：如果没有空闲帧，那么就查找当前不在使用的一个帧，并释放它。可以这样来释放一个帧：将其内容写到交换空间，并修改页表（和所有其他表），以表示该页不在内存中。现在可以使用空闲帧，来保存进程出错的页面。
+ 为实现请求调页，需要解决两个问题：**帧分配算法**和**页面置换算法**。

### 9.6 系统抖动

+ 如果进程没有需要支持活动使用页面的帧数，那么它会很快产生缺页错误。此时，必须置换某个页面。然而，由于它的所有页面都在使用中，所以必须立即置换需要再次使用的页面。因此，它会再次快速产生缺页错误，再一次置换必须立即返回的页面，如此快速进行。这种高度的页面调度活动成为**抖动（thrashing）**。如果一个进程的调页时间多于它的执行时间，那么这个进程就在抖动。
+ 通过**局部置换算法**和**优先级置换算法**可以限制系统抖动。